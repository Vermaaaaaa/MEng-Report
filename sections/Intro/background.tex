\subsection{Inertial Measurement Units (IMUs) and their applications}

\todo{IMU exists → IMU is attractive → but IMU-only drifts → so we need fusion → but fusion has failure modes → so we propose learning-aided fusion.}

IMUs are composed of multiple sensors which include a gyroscope, accelerometer, and 
occasionally a magnetometer. These three sensors measure the angular rate, 
linear acceleration, and the local magnetic field vector respectively. These measurements 
can be used to estimate the orientation of an object through integration of the angular rate. 
This data acquisition is essential for several applications such as BSNs, robotics, 
and autonomous vehicles where these systems rely on high-rate orientation updates.

IMUs have emerged as a key technology due to the ability to work in a self-
contained environment. In environments where external references of orientation are unavailable or 
unreliable, technologies such as IMUs are attractive however, they suffer from drift due to sensor 
bias and noise accumulating over time. This can be partially mitigated through the 
use of sensor fusion algorithms like Kalman filters. Filters allow the use of 
accelerometers and magnetometers to guide and correct state estimation, 
but these also suffer from failures like magnetic disturbances and high linear accelerations
corrupting a gravitational reference.
This project investigates a deep-learning model which aides sensor fusion, by providing angular
rate corrections to the filter. 